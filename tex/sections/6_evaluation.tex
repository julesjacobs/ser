\section{Evaluation}
\label{sec:evaluation}

\begin{enumerate}
    \item Benchmarks (describe our benchmarks)
    \item Results (total time, split out SMPT time from our rust code time)
    \item Analysis of optimizations (how much time they save, petri net sizes, semilinear set sizes)
    \item Limitations (examples we cannot solve, future work that would help)
\end{enumerate}


\noindent
\textbf{Experimental Setup.}
All experiments ran on a second generation Lenovo Notebook ThinkPad P16s, with 16 AMD cores and a RAM of 58 GB, with a Linux Ubuntu 24.04.2 operating system.
%
We plan on making all our code, benchmarks raw results publicly available with the final version of this paper.
 


\subsection{Benchmarks Overview}
\label{subsec:benchmarks}

\begin{itemize}
	\item \textbf{Core expressions \& multi request workflows}: Benchmarks testing arithmetic, boolean, and simple control expression.
	\item \textbf{Fred (mixed arithmetic)}: Mixed control and arithmetic transformations (Fred series).
	\item \textbf{Stop (circular-increment) series}: Circular increment loops and variants.
	\item \textbf{Concurrency \& locking loops}: Concurrent looping patterns with locking and tricky interactions.
	\item \textbf{Non-deterministic choice \& randomness}: Random choice and non-deterministic branching benchmarks.
	\item \textbf{Networking \& system protocols}: Networking protocols and system-level monitoring.
	\item \textbf{JSON state-machine examples}: Example JSON-encoded state machine workflows.
\end{itemize}



The benchmarks differ in their complexity and in the various features pertaining to them --- branching, loops, randomness, multiple requests, etc. 
%

\subsection{Runtime Results}
We ran our tool on all 47 benchmarks, out of which 27 are serializable programs, and the remaining 20 are non serializable benchmarks. 
For each benchmark, we measured the time for deciding the reachability query, indicating serializability, as well as the overall time, including validation of the invariant proof (if serializable) or the validation of the counterexample (if not serializable). These experiments ran in parallel, with $16$ cores, an a \texttt{TIMEOUT} threshold of 500 seconds and with all four optimizations. As can be seen by our results (summarized in Table~\ref{tab:benchmarks-all}), withing this time limit, our tool full solved 26/27 serializable benchmarks 
and 19/20 no serializable benchmarks. 
%
The \textit{average} certificate generation time was $39{,}613.23$ ms across all benchmarks, and $2{,}273.38$ ms ($42{,}075.84$ ms) when focusing on solely serializable (non-serializable) benchmarks.
%
The \textit{median} certificate generation time was $797$ ms across all benchmarks, and $1{,}178$ ms ($773$ ms) when focusing on solely serializable (non-serializable) benchmarks.






\begin{table}[H]
	\centering
	% Load the tabular from the external file:
	\input{tables/average_and_mean_values_of_big_table.tex}
\caption{Average and median certificate generation, certificate validation, and total running times (in ms) for serializable, non‚Äêserializable, and all benchmarks.}
\label{tab:stats-summary}
\end{table}





%=== Overall ===
%Certificate running time:
%Average = 39613.23
%Median  = 797.00
%
%Certificate validation time:
%Average = 13244.32
%Median  = 151.00
%
%Total running time:
%Average = 52857.55
%Median  = 2080.00
%
%=== Serializable Only ===
%Certificate running time:
%Average = 2273.38
%Median  = 1178.00
%
%Certificate validation time:
%Average = 23257.31
%Median  = 1299.50
%
%Total running time:
%Average = 25530.69
%Median  = 2238.50
%
%=== Non-Serializable Only ===
%Certificate running time:
%Average = 42075.84
%Median  = 773.00
%
%Certificate validation time:
%Average = 904.63
%Median  = 78.00
%
%Total running time:
%Average = 42980.47
%Median  = 830.00
%
%=== Percentiles (Overall) ===
%Certificate running time percentiles:
%25th percentile = 553.50
%50th percentile = 797.00
%100th percentile = 502810.00
%
%Certificate validation time percentiles:
%25th percentile = 66.50
%50th percentile = 151.00
%100th percentile = 282370.00
%
%Total running time percentiles:
%25th percentile = 615.00
%50th percentile = 2080.00
%100th percentile = 503336.00
%
%=== Percentiles (Serializable) ===
%Certificate running time percentiles:
%25th percentile = 312.00
%50th percentile = 1178.00
%100th percentile = 9858.00
%
%Certificate validation time percentiles:
%25th percentile = 115.75
%50th percentile = 1299.50
%100th percentile = 282370.00
%
%Total running time percentiles:
%25th percentile = 456.50
%50th percentile = 2238.50
%100th percentile = 292228.00
%
%=== Percentiles (Non-Serializable) ===
%Certificate running time percentiles:
%25th percentile = 628.50
%50th percentile = 773.00
%100th percentile = 356195.00
%
%Certificate validation time percentiles:
%25th percentile = 50.00
%50th percentile = 78.00
%100th percentile = 15227.00
%
%Total running time percentiles:
%25th percentile = 707.00
%50th percentile = 830.00
%100th percentile = 356299.00





\begin{table}[H]
	\centering
	% Load the tabular from the external file:
	\input{tables/big_table_summary.tex}
	\caption{Overview of benchmarks with combined categories and updated serializability markings. All optimizations were used, as well as a timeout value of 500 seconds.}
\label{tab:benchmarks-all}
\end{table}


\subsection{Optimization Analysis}


%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=0.4\textwidth]{plots/petri_size_reduction_plot.pdf}
%	\caption{Size reduction of Petri nets through optimization techniques. The plot shows the reduction in the number of places and transitions after applying our optimization passes. Averaged on all Petri Nets of 50 benchmarks (timeout 30 seconds).}
%	\label{fig:petri_size_reduction}
%\end{figure}


%\begin{figure}[htbp]
%	\centering
%	\includegraphics[width=0.4\textwidth]{plots/timeout_10000_cumulative_solved_linear.pdf}
%	\caption{Size reduction of Petri nets through optimization techniques. The plot shows the reduction in the number of places and transitions after applying our optimization passes. Averaged on all Petri Nets of 50 benchmarks (timeout 30 seconds).}
%	\label{fig:runtime}
%\end{figure}



\begin{center}
		\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/cactus_plot.pdf}
		\captionof{figure}{Cumulative number of solved instances over time with a 150-second timeout.}
		\label{fig:timeout_cumulative_solved_log}
	\end{minipage}\hfill
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/petri_size_reduction_plot.pdf}
		\captionof{figure}{Reduction of Petri nets size (places and transitions) via bidirectional pruning 
%(timeout 150 seconds)
.}
		\label{fig:petri_size_reduction}
	\end{minipage}
\end{center}







\begin{table}[H]
	\centering
	% Load the tabular from the external file:
	\input{tables/semilinear_size_reduction.tex}
	\caption{Comparison of experiment runs with a 150-second timeout.}
	\label{tab:semilinear-size-reduction}
\end{table}


\newpage





%\section{Comprehensive Statistics}
%\begin{table}[H]
%	\centering
%	\input{tables/comprehensive\_stats.tex}
%	\caption{Comprehensive statistics}
%	\label{tab:comprehensive\_stats}
%\end{table}
%
%\section{Pruning Effectiveness}
%\begin{table}[H]
%	\centering
%	\input{tables/pruning_effectiveness.tex}
%	\caption{Petri net pruning effectiveness}
%	\label{tab:pruning\_effectiveness}
%\end{table}
%
%\section{Timing Comparison}
%\begin{table}[H]
%	\centering
%	\input{tables/timing_comparison.tex}
%	\caption{Comparison of optimized vs.\ unoptimized run times}
%	\label{tab:timing\_comparison}
%\end{table}
%
%\section{Optimization Breakdown}
%\begin{table}[H]
%	\centering
%	\input{tables/optimization_breakdown.tex}
%	\caption{Impact of individual optimizations}
%	\label{tab:optimization\_breakdown}
%\end{table}
%
%\section{Summary Statistics}
%\begin{table}[H]
%	\centering
%	\input{tables/summary_stats.tex}
%	\caption{Overall summary statistics}
%	\label{tab:summary\_stats}
%\end{table}